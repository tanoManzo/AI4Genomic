{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETro9oX0g4kH"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install git+https://www.github.com/huggingface/transformers\n",
        "#!pip install git+https://github.com/huggingface/accelerate\n",
        "#!pip install bitsandbytes\n",
        "#!pip install einops\n",
        "#!pip install --upgrade torch torchvision\n",
        "#!pip install scikit-learn\n",
        "#!pip install matplotlib\n",
        "#!pip install datasets\n",
        "#!pip install Bio\n",
        "#!pip install pybedtools\n",
        "#!pip install tabulate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I320YzvVg4kF"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7jNiPHkIg4kI"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, TrainingArguments, Trainer, AutoModelForSequenceClassification,BertForSequenceClassification, AutoModel, AutoConfig\n",
        "from transformers.models.bert.configuration_bert import BertConfig\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "from sklearn import metrics \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from Bio import SeqIO\n",
        "from pybedtools import BedTool\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import importlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "sns.set()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Transformer Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_models_and_tokenizers(models_names, bios_id, ft_model_type):\n",
        "    models_tokenizers_dict = {}\n",
        "\n",
        "    for model_name in models_names:\n",
        "        model_ckpt = f\"tanoManzo/{model_name}_ft_{bios_id}_{ft_model_type}\"\n",
        "        print(f\"Loading model and tokenizer for: {model_ckpt}\")\n",
        "\n",
        "        try:\n",
        "            # Load DNABERT model\n",
        "            if 'dnabert2' in model_ckpt:\n",
        "               model = BertForSequenceClassification.from_pretrained(model_ckpt, trust_remote_code=True)\n",
        "               tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "            \n",
        "            # Load Geneformer model\n",
        "            elif 'Geneformer' in model_ckpt:\n",
        "                tokenizer = AutoTokenizer.from_pretrained('tanoManzo/Geneformer_ft_Hepg2_1kbpHG19_DHSs_H3K27AC')\n",
        "                model = AutoModelForSequenceClassification.from_pretrained(model_ckpt)\n",
        "\n",
        "            # Load Gena models\n",
        "            elif 'gena-' in model_ckpt:\n",
        "                model = AutoModel.from_pretrained(model_ckpt, trust_remote_code=True)\n",
        "                gena_module_name = model.__class__.__module__\n",
        "\n",
        "                # BigBird model under Gena\n",
        "                if 'bigbird' in model_ckpt:\n",
        "                    cls = getattr(importlib.import_module(gena_module_name), 'BigBirdForSequenceClassification')\n",
        "                else:\n",
        "                    cls = getattr(importlib.import_module(gena_module_name), 'BertForSequenceClassification')\n",
        "                \n",
        "                model = cls.from_pretrained(model_ckpt, num_labels=2)\n",
        "                tokenizer = AutoTokenizer.from_pretrained(model_ckpt, trust_remote_code=True)\n",
        "\n",
        "            # Load generic model\n",
        "            else:\n",
        "                tokenizer = AutoTokenizer.from_pretrained(model_ckpt, trust_remote_code=True)\n",
        "                model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, trust_remote_code=True)\n",
        "\n",
        "            # Store the model and tokenizer in a dictionary\n",
        "            models_tokenizers_dict[f\"{model_name}_ft_{bios_id}\"] = {'model': model, 'tokenizer': tokenizer}\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {model_ckpt}: {str(e)}\")\n",
        "\n",
        "    return models_tokenizers_dict\n",
        "\n",
        "# Example usage\n",
        "#models_tokenizers_dict = load_models_and_tokenizers(models_names, bios_id, ft_model_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq84tE1Zg4kJ"
      },
      "source": [
        "## Datasetes"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### get fasta hg19/hg38 database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_chrom2seq(fasta_file, capitalize=True):\n",
        "\n",
        "    chrom2seq = {}\n",
        "    for seq in SeqIO.parse(fasta_file, \"fasta\"):\n",
        "        chrom2seq[seq.description.split()[0]] = seq.seq.upper() if capitalize else seq.seq\n",
        "\n",
        "    return chrom2seq\n",
        "# Example usage\n",
        "#chrom2seq = get_chrom2seq(FASTA_FILE_19)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "def data_preprocessing(type_data,name_data,dataset_path):\n",
        "    \n",
        "    updated_data_df = pd.DataFrame()\n",
        "    path_file = f\"{dataset_path}/{type_data}/{name_data}\"\n",
        "\n",
        "    if type_data == 'raQTL':\n",
        "        old_data_df = pd.read_csv(path_file, sep='\\t')\n",
        "        updated_data_df['Chromosome'] = old_data_df['chr']\n",
        "        updated_data_df['Position'] = old_data_df['SNPabspos']\n",
        "        updated_data_df['Reference'] = old_data_df['ref']\n",
        "        updated_data_df['Alternative'] = old_data_df['alt']\n",
        "        updated_data_df['Value_Ratio'] = old_data_df['hepg2.alt.mean']/old_data_df['hepg2.ref.mean']\n",
        "        updated_data_df['Value_Diff'] = old_data_df['hepg2.alt.mean']-old_data_df['hepg2.ref.mean']\n",
        "        updated_data_df['Value_Pvalue_signed'] = -np.log10(old_data_df['hepg2.wilcox.p.value'])*np.sign(updated_data_df['Value_Diff'])\n",
        "        updated_data_df['P_value'] = old_data_df['hepg2.wilcox.p.value']\n",
        "    \n",
        "    return updated_data_df\n",
        "\n",
        "# Example usage\n",
        "#data_df = data_preprocessing(type_data,name_data,dataset_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extract Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_sequences(data_df, chrom2seq, length_bp=999):\n",
        "    \"\"\"\n",
        "    Process sequences from a DataFrame and extract reference and alternative sequences.\n",
        "\n",
        "    Parameters:\n",
        "        mpra_df (pd.DataFrame): DataFrame containing chromosome, position, alt, and p-value columns.\n",
        "        chrom2seq (dict): Dictionary mapping chromosomes to sequence data.\n",
        "        length_bp (int): Length of the sequence to extract centered around each position.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing three lists:\n",
        "            - seq_ref (list): List of reference sequences.\n",
        "            - seq_alt (list): List of alternative sequences.\n",
        "            - seq_val (list): List of values.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    seq_ref = []\n",
        "    seq_alt = []\n",
        "    \n",
        "\n",
        "    # Iterate over the DataFrame rows\n",
        "    for idx, row in data_df.iterrows():\n",
        "        chromosome = f\"{row['Chromosome']}\"\n",
        "        abspos = row['Position']\n",
        "        \n",
        "        # Calculate the start and end positions for the sequence extraction\n",
        "        start_pos = abspos - (length_bp // 2)-1\n",
        "        end_pos = abspos + (length_bp // 2)  # Add 1 to ensure the length is exactly 1000 bp\n",
        "        \n",
        "        # Extract the sequence from the chromosome data\n",
        "        seq = str(chrom2seq[chromosome][start_pos:end_pos])\n",
        "        if len(seq) != length_bp:\n",
        "            raise ValueError(f\"Extracted sequence length {len(seq)} does not match the expected length {length_bp}.\")\n",
        "        \n",
        "        half_len = len(seq) // 2\n",
        "\n",
        "        #seq_ref.append(seq)\n",
        "        seq_ref.append(f\"{seq[:half_len]}{row['Reference']}{seq[half_len + 1:]}\")\n",
        "        \n",
        "\n",
        "        # Create the alternative sequence by replacing the middle base with 'Alt'\n",
        "        seq_alt.append(f\"{seq[:half_len]}{row['Alternative']}{seq[half_len + 1:]}\")\n",
        "\n",
        "        if seq[half_len]!= row['Reference'] and seq[half_len]!= row['Alternative']:\n",
        "            print(\"Warning Nucleaotide does NOT matched Ref or Alt\")\n",
        "\n",
        "    data_df['Seq_Reference'] = seq_ref\n",
        "    data_df['Seq_Alternative'] = seq_alt\n",
        "    return data_df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get model predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Function to get predictions in batches\n",
        "def get_predictions_raw(models_tokenizers_dict, seq_ref, seq_alt, device=\"cuda\", batch_size=32):\n",
        "    models_predictions = {}\n",
        "\n",
        "    def tokenize_in_batches(sequence, tokenizer, max_length=512, batch_size=32):\n",
        "        tokens = tokenizer(sequence, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
        "        for i in range(0, tokens['input_ids'].size(0), batch_size):\n",
        "            yield {k: v[i:i+batch_size].to(device) for k, v in tokens.items()}\n",
        "\n",
        "    for model_name, item in models_tokenizers_dict.items():\n",
        "        model = item['model'].to(device).eval()\n",
        "        tokenizer = item['tokenizer']\n",
        "\n",
        "        print(f\"Processing model: {model_name}\")\n",
        "\n",
        "        outputs_ref = []\n",
        "        outputs_alt = []\n",
        "\n",
        "        # Process in batches\n",
        "        for inputs_ref in tokenize_in_batches(seq_ref, tokenizer, batch_size=batch_size):\n",
        "            with torch.no_grad():\n",
        "                batch_outputs_ref = model(**inputs_ref).logits.cpu()\n",
        "                outputs_ref.append(batch_outputs_ref)\n",
        "            torch.cuda.empty_cache()  # Clear memory after each batch\n",
        "\n",
        "        for inputs_alt in tokenize_in_batches(seq_alt, tokenizer, batch_size=batch_size):\n",
        "            with torch.no_grad():\n",
        "                batch_outputs_alt = model(**inputs_alt).logits.cpu()\n",
        "                outputs_alt.append(batch_outputs_alt)\n",
        "            torch.cuda.empty_cache()  # Clear memory after each batch\n",
        "\n",
        "        # Concatenate all batch results\n",
        "        outputs_ref = torch.cat(outputs_ref, dim=0)\n",
        "        outputs_alt = torch.cat(outputs_alt, dim=0)\n",
        "\n",
        "        # Store results in CPU memory\n",
        "        models_predictions[model_name] = {'ref': outputs_ref, 'alt': outputs_alt}\n",
        "\n",
        "        # Free GPU memory by moving model to CPU and clearing cache\n",
        "        model.to(\"cpu\")\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return models_predictions\n",
        "\n",
        "# Usage\n",
        "#models_predictions = get_predictions_raw(models_tokenizers_dict, data_df['Seq_Reference'].to_list(), data_df['Seq_Alternative'].to_list() , batch_size=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_delta(outputs_ref_cpu, outputs_alt_cpu, seq_val):\n",
        "    delta_ref = outputs_ref_cpu[:,1] - outputs_ref_cpu[:,0]\n",
        "    delta_alt = outputs_alt_cpu[:,1] - outputs_alt_cpu[:,0]\n",
        "\n",
        "    # Calculate the difference in logits between alternative and reference sequences\n",
        "    log2_fold_change =  np.log2(torch.sigmoid(delta_alt)/torch.sigmoid(delta_ref))\n",
        "    diff_alt_ref =  np.array(delta_alt)-np.array(delta_ref)\n",
        "\n",
        "    # Compute the difference in the logit values for the positive class (enhancer)     \n",
        "    log2_variant_expression_effect = np.log2(seq_val) \n",
        "            \n",
        "    return np.array(log2_fold_change), log2_variant_expression_effect"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_regression_and_correlation(deltas):\n",
        "    slope, intercept, r_val, p_val, std_err = stats.linregress(deltas)\n",
        "    spearman_corr = stats.spearmanr(deltas[0], deltas[1]).correlation\n",
        "    return slope, intercept, r_val, p_val, std_err, spearman_corr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model and tokenizer for: tanoManzo/dnabert2_ft_BioS73_1kbpHG19_DHSs_H3K27AC\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a6482a4e34b41e5825898a5b2624b69",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/357M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# data path repo\n",
        "dataset_path = \"/data/Dcode/gaetano/repos/AI4Genomic/data\"\n",
        "\n",
        "# model name from huggingface.co/model name_id:model_name\n",
        "models_names = [\n",
        " 'dnabert2',\n",
        " #'nucleotide-transformer-v2-50m-multi-species',\n",
        " #'nucleotide-transformer-v2-100m-multi-species',\n",
        " #'nucleotide-transformer-v2-250m-multi-species',\n",
        " #'nucleotide-transformer-v2-500m-multi-species',\n",
        " #'nucleotide-transformer-500m-1000g',\n",
        " #'nucleotide-transformer-500m-human-ref',\n",
        " #'nucleotide-transformer-2.5b-1000g',\n",
        " #'nucleotide-transformer-2.5b-multi-species',\n",
        " #'Geneformer',\n",
        " #'gena-lm-bert-base-t2t',\n",
        " #'gena-lm-bert-large-t2t',\n",
        " #'gena-lm-bert-base-t2t-multi',\n",
        " #'gena-lm-bigbird-base-t2t',\n",
        " #'hyenadna-small-32k-seqlen-hf',\n",
        " #'hyenadna-medium-160k-seqlen-hf',\n",
        " #'hyenadna-medium-450k-seqlen-hf',\n",
        " #'hyenadna-large-1m-seqlen-hf'\n",
        " ]\n",
        "\n",
        "# type of fine-tuned\n",
        "ft_model_type = '1kbpHG19_DHSs_H3K27AC'\n",
        "\n",
        "# samples for fine-tuning\n",
        "#'BioS2'=Hela, 'BioS45'=neural progenitor cell, 'BioS73'=hepg2, 'BioS74'=k562\n",
        "bios_ids = ['BioS2', 'BioS45', 'BioS73', 'BioS74']\n",
        "\n",
        "FASTA_FILE_19 = \"/data/Dcode/gaetano/repos/fasta_files/hg19.fa\"\n",
        "FASTA_FILE_38 = \"/data/Dcode/gaetano/repos/fasta_files/hg38.fa\"\n",
        "\n",
        "bios_id = \"BioS73\"\n",
        "models_tokenizers_dict = load_models_and_tokenizers(models_names, bios_id, ft_model_type)\n",
        "\n",
        "chrom2seq = get_chrom2seq(FASTA_FILE_19)\n",
        "\n",
        "dataset_path = \"/data/Dcode/gaetano/repos/AI4Genomic/data\"\n",
        "type_data = 'raQTL'\n",
        "name_data = 'hepg2.sign.id.LP190708.txt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing model: dnabert2_ft_BioS73\n",
            "(13.140624943004761, 0.9880731812586995, 0.40957110265799423, 2.3225334722565703e-05, 2.9566571764360727, 0.422106210621062)\n"
          ]
        }
      ],
      "source": [
        "data_df = data_preprocessing(type_data, name_data, dataset_path)\n",
        "data_df = process_sequences(data_df, chrom2seq)\n",
        "data_df = data_df.iloc[:100]\n",
        "\n",
        "models_predictions = get_predictions_raw(models_tokenizers_dict, data_df['Seq_Reference'].to_list(), data_df['Seq_Alternative'].to_list() , batch_size=8)\n",
        "\n",
        "for model_name in models_predictions.keys():\n",
        "    out_ref = models_predictions[model_name]['ref']\n",
        "    out_alt = models_predictions[model_name]['alt']\n",
        "\n",
        "    log2_prediction, log2_exp = compute_delta(out_ref, out_alt, data_df['Value_Ratio'].to_list())\n",
        "    models_predictions[model_name]['log2_prediction'] = log2_prediction\n",
        "\n",
        "    print(compute_regression_and_correlation((log2_prediction, log2_exp)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dnabert2_ft_BioS73': {'ref': tensor([[ 0.0387, -0.2584],\n",
              "          [ 1.0463, -1.4867],\n",
              "          [ 0.5962, -0.9592],\n",
              "          [ 0.4781, -0.8132],\n",
              "          [ 0.5145, -0.8579],\n",
              "          [ 1.1292, -1.5772],\n",
              "          [ 0.0583, -0.2877],\n",
              "          [ 0.2440, -0.5298],\n",
              "          [-0.3360,  0.2572],\n",
              "          [ 0.4126, -0.7133],\n",
              "          [-0.8249,  0.9355],\n",
              "          [ 1.2763, -1.7423],\n",
              "          [ 1.3494, -1.8104],\n",
              "          [-1.2690,  1.4577],\n",
              "          [-1.0124,  1.1699],\n",
              "          [ 1.2426, -1.7074],\n",
              "          [ 1.3365, -1.7981],\n",
              "          [-0.3579,  0.3120],\n",
              "          [-0.9870,  1.1271],\n",
              "          [-0.9789,  1.1178],\n",
              "          [-0.7929,  0.8970],\n",
              "          [-1.2418,  1.4284],\n",
              "          [-0.8016,  0.8989],\n",
              "          [ 0.0971, -0.3225],\n",
              "          [-0.3315,  0.2520],\n",
              "          [-0.8031,  0.9029],\n",
              "          [-0.6470,  0.6817],\n",
              "          [-0.8435,  0.9565],\n",
              "          [-0.5263,  0.5278],\n",
              "          [-0.3140,  0.2487],\n",
              "          [-0.2650,  0.1573],\n",
              "          [-1.2956,  1.4912],\n",
              "          [-0.3229,  0.2201],\n",
              "          [ 1.3060, -1.7684],\n",
              "          [-0.6325,  0.6826],\n",
              "          [-0.6979,  0.7489],\n",
              "          [ 0.2315, -0.4785],\n",
              "          [ 1.1531, -1.6066],\n",
              "          [-0.8744,  0.9887],\n",
              "          [ 0.4303, -0.7528],\n",
              "          [-0.2770,  0.1742],\n",
              "          [-0.9481,  1.0757],\n",
              "          [-0.9819,  1.1118],\n",
              "          [-0.3776,  0.3366],\n",
              "          [ 1.2003, -1.6648],\n",
              "          [-1.0344,  1.1805],\n",
              "          [ 0.9479, -1.3673],\n",
              "          [-1.0613,  1.2153],\n",
              "          [ 0.8247, -1.2303],\n",
              "          [ 0.4274, -0.7326],\n",
              "          [ 0.8691, -1.2778],\n",
              "          [-0.2444,  0.1241],\n",
              "          [-0.2279,  0.0890],\n",
              "          [ 0.7776, -1.1690],\n",
              "          [ 0.0624, -0.2930],\n",
              "          [ 0.2528, -0.5163],\n",
              "          [ 1.1845, -1.6390],\n",
              "          [-0.8914,  1.0167],\n",
              "          [-0.2657,  0.1824],\n",
              "          [-0.8164,  0.9075],\n",
              "          [ 0.5585, -0.9114],\n",
              "          [ 0.6413, -0.9954],\n",
              "          [ 0.4535, -0.7756],\n",
              "          [-0.2875,  0.1836],\n",
              "          [-1.2233,  1.4064],\n",
              "          [-0.3459,  0.2639],\n",
              "          [ 0.7727, -1.1618],\n",
              "          [ 0.0150, -0.2083],\n",
              "          [ 1.0041, -1.4380],\n",
              "          [ 0.7635, -1.1476],\n",
              "          [ 0.4775, -0.8002],\n",
              "          [-1.0677,  1.2242],\n",
              "          [ 0.3306, -0.6195],\n",
              "          [-1.3004,  1.5006],\n",
              "          [ 1.3425, -1.8094],\n",
              "          [-0.8029,  0.9188],\n",
              "          [-0.0994, -0.0666],\n",
              "          [-1.0862,  1.2465],\n",
              "          [-1.3300,  1.5361],\n",
              "          [ 1.2879, -1.7466],\n",
              "          [ 0.3795, -0.6931],\n",
              "          [ 1.0321, -1.4708],\n",
              "          [-0.5907,  0.6267],\n",
              "          [ 1.0759, -1.5210],\n",
              "          [-0.5313,  0.5361],\n",
              "          [-0.8808,  1.0136],\n",
              "          [ 1.2784, -1.7459],\n",
              "          [ 0.7742, -1.1576],\n",
              "          [-0.4351,  0.3949],\n",
              "          [-0.9811,  1.1222],\n",
              "          [ 0.1833, -0.4388],\n",
              "          [-0.6661,  0.7296],\n",
              "          [-0.9336,  1.0535],\n",
              "          [ 0.2481, -0.5164],\n",
              "          [-0.7991,  0.9157],\n",
              "          [ 0.0346, -0.2479],\n",
              "          [-0.4907,  0.5058],\n",
              "          [ 1.1456, -1.6123],\n",
              "          [ 0.9659, -1.3921],\n",
              "          [ 1.0518, -1.4962]]),\n",
              "  'alt': tensor([[-0.0773, -0.1078],\n",
              "          [ 1.0192, -1.4540],\n",
              "          [ 0.6031, -0.9664],\n",
              "          [ 0.3877, -0.7034],\n",
              "          [ 0.5429, -0.8932],\n",
              "          [ 1.1482, -1.5992],\n",
              "          [ 0.0887, -0.3262],\n",
              "          [ 0.1602, -0.4263],\n",
              "          [-0.3479,  0.2724],\n",
              "          [ 0.4437, -0.7520],\n",
              "          [-0.8462,  0.9623],\n",
              "          [ 1.2740, -1.7402],\n",
              "          [ 1.3433, -1.8047],\n",
              "          [-1.2757,  1.4658],\n",
              "          [-1.0063,  1.1624],\n",
              "          [ 1.2352, -1.7001],\n",
              "          [ 1.3384, -1.8001],\n",
              "          [-0.2610,  0.1699],\n",
              "          [-0.9708,  1.1079],\n",
              "          [-1.0334,  1.1835],\n",
              "          [-0.7774,  0.8779],\n",
              "          [-1.2221,  1.4049],\n",
              "          [-0.7967,  0.8946],\n",
              "          [ 0.0225, -0.2282],\n",
              "          [-0.4105,  0.3668],\n",
              "          [-0.8038,  0.9034],\n",
              "          [-0.6690,  0.7122],\n",
              "          [-0.8773,  0.9999],\n",
              "          [-0.5647,  0.5809],\n",
              "          [-0.2946,  0.2190],\n",
              "          [-0.2328,  0.1103],\n",
              "          [-1.2988,  1.4955],\n",
              "          [-0.2944,  0.1789],\n",
              "          [ 1.2954, -1.7579],\n",
              "          [-0.6684,  0.7320],\n",
              "          [-0.7041,  0.7568],\n",
              "          [ 0.1071, -0.3229],\n",
              "          [ 1.1486, -1.6003],\n",
              "          [-0.8540,  0.9634],\n",
              "          [ 0.3643, -0.6720],\n",
              "          [-0.2697,  0.1628],\n",
              "          [-0.9723,  1.1059],\n",
              "          [-0.9935,  1.1262],\n",
              "          [-0.3749,  0.3333],\n",
              "          [ 1.1975, -1.6619],\n",
              "          [-1.0284,  1.1730],\n",
              "          [ 0.8609, -1.2600],\n",
              "          [-1.0595,  1.2140],\n",
              "          [ 0.8354, -1.2433],\n",
              "          [ 0.4128, -0.7142],\n",
              "          [ 0.8630, -1.2710],\n",
              "          [-0.2485,  0.1294],\n",
              "          [-0.2333,  0.0966],\n",
              "          [ 0.8608, -1.2713],\n",
              "          [ 0.1862, -0.4481],\n",
              "          [ 0.1821, -0.4283],\n",
              "          [ 1.1779, -1.6312],\n",
              "          [-0.9300,  1.0648],\n",
              "          [-0.2499,  0.1599],\n",
              "          [-0.8274,  0.9219],\n",
              "          [ 0.4546, -0.7842],\n",
              "          [ 0.6374, -0.9906],\n",
              "          [ 0.4227, -0.7380],\n",
              "          [-0.2784,  0.1711],\n",
              "          [-1.2261,  1.4103],\n",
              "          [-0.3457,  0.2647],\n",
              "          [ 0.7575, -1.1427],\n",
              "          [-0.1017, -0.0541],\n",
              "          [ 0.9400, -1.3600],\n",
              "          [ 0.6562, -1.0159],\n",
              "          [ 0.5732, -0.9178],\n",
              "          [-1.0749,  1.2327],\n",
              "          [ 0.3281, -0.6170],\n",
              "          [-1.2839,  1.4808],\n",
              "          [ 1.3398, -1.8070],\n",
              "          [-0.7941,  0.9089],\n",
              "          [-0.0172, -0.1745],\n",
              "          [-1.0703,  1.2276],\n",
              "          [-1.3093,  1.5116],\n",
              "          [ 1.2909, -1.7497],\n",
              "          [ 0.4660, -0.7988],\n",
              "          [ 1.0468, -1.4867],\n",
              "          [-0.5765,  0.6074],\n",
              "          [ 1.0630, -1.5055],\n",
              "          [-0.5703,  0.5925],\n",
              "          [-0.8998,  1.0366],\n",
              "          [ 1.2803, -1.7476],\n",
              "          [ 0.8230, -1.2184],\n",
              "          [-0.4379,  0.4004],\n",
              "          [-0.9651,  1.1016],\n",
              "          [ 0.2152, -0.4777],\n",
              "          [-0.6499,  0.7067],\n",
              "          [-0.9508,  1.0756],\n",
              "          [ 0.4627, -0.7788],\n",
              "          [-0.8006,  0.9172],\n",
              "          [ 0.0604, -0.2811],\n",
              "          [-0.4874,  0.5005],\n",
              "          [ 1.0863, -1.5456],\n",
              "          [ 0.8501, -1.2507],\n",
              "          [ 0.9991, -1.4327]]),\n",
              "  'log2_prediction': array([ 2.0795684e-01,  7.9831593e-02, -1.6769513e-02,  2.2157532e-01,\n",
              "         -7.3703736e-02, -5.5631801e-02, -5.8990553e-02,  1.7930381e-01,\n",
              "          1.3793587e-02, -7.6686300e-02,  9.9652624e-03,  5.9056473e-03,\n",
              "          1.6313020e-02,  1.2977131e-03, -2.0055932e-03,  2.0109974e-02,\n",
              "         -5.3884638e-03, -1.2613989e-01, -5.5831992e-03,  1.7984314e-02,\n",
              "         -7.9047848e-03, -4.1207364e-03, -2.0672500e-03,  1.4211267e-01,\n",
              "          9.4048359e-02,  2.6276556e-04,  1.5525138e-02,  1.5279943e-02,\n",
              "          3.2974422e-02, -2.6100792e-02, -4.6365771e-02,  6.2639680e-04,\n",
              "         -3.7752025e-02,  2.9138410e-02,  2.5195673e-02,  3.8477916e-03,\n",
              "          2.5794700e-01,  1.4747380e-02, -9.0435296e-03,  1.5929671e-01,\n",
              "         -1.0553179e-02,  8.9496775e-03,  4.0717851e-03, -2.8655813e-03,\n",
              "          7.8495648e-03, -1.9347257e-03,  2.5261706e-01, -4.2451563e-04,\n",
              "         -3.0248655e-02,  3.6157846e-02,  1.6739100e-02,  5.5844611e-03,\n",
              "          7.9113124e-03, -2.3684976e-01, -2.5005192e-01,  1.5250875e-01,\n",
              "          1.9735275e-02,  1.5551000e-02, -2.1770652e-02,  5.4938309e-03,\n",
              "          2.6495224e-01,  1.0504374e-02,  7.5867712e-02, -1.2103691e-02,\n",
              "          6.5011991e-04,  2.8529100e-04,  4.3107741e-02,  2.0391670e-01,\n",
              "          1.8743287e-01,  2.9537672e-01, -2.4605747e-01,  2.0726211e-03,\n",
              "          5.1900325e-03, -3.0434311e-03,  7.1337163e-03, -4.1072834e-03,\n",
              "         -1.4140312e-01, -4.5054057e-03, -3.5909053e-03, -8.4682070e-03,\n",
              "         -2.1152361e-01, -4.0789809e-02, -1.1175783e-02,  3.8142353e-02,\n",
              "          3.3996589e-02,  7.7799461e-03, -4.9886308e-03, -1.3902141e-01,\n",
              "          3.6719681e-03, -5.8432329e-03, -6.7203589e-02, -1.1378842e-02,\n",
              "          6.7282422e-03, -5.0287813e-01,  6.7848398e-04, -4.9144950e-02,\n",
              "         -3.3383451e-03,  1.7016774e-01,  3.3504122e-01,  1.5467320e-01],\n",
              "        dtype=float32)}}"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "models_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'filter_significant' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[40], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     spearman_corr \u001b[38;5;241m=\u001b[39m stats\u001b[38;5;241m.\u001b[39mspearmanr(deltas[\u001b[38;5;241m0\u001b[39m], deltas[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mcorrelation\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m slope, intercept, r_val, p_val, std_err, spearman_corr\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_linregress_stats\u001b[39m(model, model_predictions, seq_val, significance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, filter_significant\u001b[38;5;241m=\u001b[39m\u001b[43mfilter_significant\u001b[49m):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrednet\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnformer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSei\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mborzoi\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     11\u001b[0m         deltas \u001b[38;5;241m=\u001b[39m compute_delta_trednet_sei_enformer_borzoi(model_predictions, seq_val)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'filter_significant' is not defined"
          ]
        }
      ],
      "source": [
        "from scipy import stats\n",
        "from typing import Callable, Tuple, Dict, Any\n",
        "\n",
        "def compute_regression_and_correlation(deltas):\n",
        "    slope, intercept, r_val, p_val, std_err = stats.linregress(deltas)\n",
        "    spearman_corr = stats.spearmanr(deltas[0], deltas[1]).correlation\n",
        "    return slope, intercept, r_val, p_val, std_err, spearman_corr\n",
        "\n",
        "def get_linregress_stats(model, model_predictions, seq_val, significance=True, filter_significant=filter_significant):\n",
        "    if model in ['trednet', 'Enformer', 'Sei', 'borzoi']:\n",
        "        deltas = compute_delta_trednet_sei_enformer_borzoi(model_predictions, seq_val)\n",
        "    else:\n",
        "        outputs_ref_cpu, outputs_alt_cpu = model_predictions.values()\n",
        "        deltas = compute_delta(outputs_ref_cpu, outputs_alt_cpu, seq_val)\n",
        "\n",
        "    if significance:\n",
        "        deltas =  np.array(deltas[0])[filter_significant],  np.array(deltas[1])[filter_significant]\n",
        "    \n",
        "    return compute_regression_and_correlation(deltas), deltas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TredNet & Sei & Enformer & Borzoi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_to_add = ['trednet', 'Sei', 'Enformer', 'borzoi']\n",
        "models_names += [model for model in models_to_add if model not in models_names]\n",
        "models_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load predictions "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load TredNet predictions\n",
        "with open(\"/data/Dcode/gaetano/repos/Transformers4Genomic/data/mpra/trednet_predictions_GSE68331.pkl\", 'rb') as f:\n",
        "    data = pickle.load(f, encoding='latin1')\n",
        "    outputs_ref_cpu_tred = np.squeeze(data['predictions_ref'])\n",
        "    outputs_alt_cpu_tred = np.squeeze(data['predictions_alt'])\n",
        "    models_predictions['trednet'] = outputs_alt_cpu_tred/outputs_ref_cpu_tred\n",
        "\n",
        "\n",
        "path_sei_pred = \"/data/Dcode/gaetano/CNNplusModels/sei-framework/sei_mpra_GSE68331_prediction_diff_full.pkl\"\n",
        "with open(path_sei_pred, 'rb') as f:\n",
        "    data = pickle.load(f, encoding='latin1')\n",
        "    delta_sei_out = np.squeeze(data['diff_ratio'])\n",
        "models_predictions['Sei'] = delta_sei_out\n",
        "\n",
        "\n",
        "# Load Enformer predictions\n",
        "with open(\"/data/Dcode/gaetano/CNNplusModels/enformer-pytorch/enformer_mpra_GSE68331_prediction_diff_full.pkl\", 'rb') as f:\n",
        "    data = pickle.load(f, encoding='latin1')\n",
        "    delta_enformer_out = np.squeeze(data['diff_ratio'])\n",
        "models_predictions['Enformer'] = delta_enformer_out\n",
        "\n",
        "\n",
        "# Load borzoi predictions\n",
        "with open(\"/data/Dcode/gaetano/CNNplusModels/baskerville/borzoi/examples/borzoi_models_sample/results/borzoi_mpra_GSE68_prediction_diff_full.pkl\", 'rb') as f:\n",
        "    data = pickle.load(f, encoding='latin1')\n",
        "    delta_borzoi_out = np.squeeze(data['diff_ratio'])\n",
        "models_predictions['borzoi'] = delta_borzoi_out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Delta Computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_delta(outputs_ref_cpu, outputs_alt_cpu, seq_val):\n",
        "    delta_ref = outputs_ref_cpu[:,0] - outputs_ref_cpu[:,1]\n",
        "    delta_alt = outputs_alt_cpu[:,0] - outputs_alt_cpu[:,1]\n",
        "\n",
        "    # Calculate the difference in logits between alternative and reference sequences\n",
        "    fold_change =  np.array(delta_alt)/np.array(delta_ref)\n",
        "    #fold_change =  np.array(delta_alt)-np.array(delta_ref)\n",
        "\n",
        "    # Compute the difference in the logit values for the positive class (enhancer)     \n",
        "    log2_variant_expression_effect = np.log2(fold_change) \n",
        "    #log2_variant_expression_effect = fold_change\n",
        "\n",
        "    # Compute the difference in expression between alt and ref\n",
        "    log2_exp = []\n",
        "    log2_variant_expression_filter = []\n",
        "    for s_m, s_v in zip(log2_variant_expression_effect,seq_val):\n",
        "        if not np.isnan(s_m):\n",
        "            log2_exp.append(s_v)\n",
        "            log2_variant_expression_filter.append(s_m)\n",
        "        else:\n",
        "            log2_exp.append(s_v)\n",
        "            log2_variant_expression_filter.append(0)\n",
        "            \n",
        "    return log2_exp, log2_variant_expression_filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_delta_trednet_sei_enformer_borzoi(outputs_cpu, seq_val):\n",
        "    # Calculate the difference in logits between alternative and reference sequences\n",
        "    fold_change =  outputs_cpu\n",
        "\n",
        "    # Compute the difference in the logit values for the positive class (enhancer)\n",
        "    log2_variant_expression_effect = np.log2(fold_change) \n",
        "    #log2_variant_expression_effect = fold_change \n",
        "    \n",
        "    # Compute the difference in expression between alt and ref\n",
        "    log2_exp = []\n",
        "    log2_variant_expression_filter = []\n",
        "    for s_m, s_v in zip(log2_variant_expression_effect,seq_val):\n",
        "        if not np.isnan(s_m):\n",
        "            log2_exp.append(s_v)\n",
        "            log2_variant_expression_filter.append(s_m)\n",
        "            \n",
        "    return log2_exp, log2_variant_expression_filter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import List, Tuple, Any, Dict\n",
        "\n",
        "def plot_regression(df_significant, df_all, model, r_val_significant, p_val_significant, r_val_all, p_val_all):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    \n",
        "    # Plot non-significant data (all data)\n",
        "    sns.regplot(\n",
        "        x='Model Output Difference',\n",
        "        y='Expression Difference',\n",
        "        data=df_all,\n",
        "        scatter_kws={'alpha': 0.1, 'color': 'blue'},\n",
        "        line_kws={'color': 'blue', 'label': f'All Data: r={r_val_all:.3f}, p={p_val_all:.3f}'}\n",
        "    )\n",
        "    \n",
        "    # Plot significant data\n",
        "    sns.regplot(\n",
        "        x='Model Output Difference',\n",
        "        y='Expression Difference',\n",
        "        data=df_significant,\n",
        "        scatter_kws={'alpha': 0.5, 'color': 'red'},\n",
        "        line_kws={'color': 'red', 'label': f'Significant Data: r={r_val_significant:.3f}, p={p_val_significant:.3f}'}\n",
        "    )\n",
        "    \n",
        "    plt.ylabel('Expression Value log2(Alternative/Reference)')\n",
        "    plt.xlabel('Model Output Value log2(Alternative/Reference)')\n",
        "    plt.title(f'{model}')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def process_models(models_names, models_predictions, seq_val):\n",
        "    for model in models_names:\n",
        "        # Fetch the model statistics and deltas for significant data\n",
        "        (slope_significant, intercept_significant, r_val_significant, p_val_significant, std_err_significant, spearman_corr_significant), (delta_exp_significant, delta_model_out_significant) = get_linregress_stats(model, models_predictions[model], seq_val, True, filter_significant)\n",
        "        \n",
        "        # Fetch the model statistics and deltas for all data (non-significant included)\n",
        "        (slope_all, intercept_all, r_val_all, p_val_all, std_err_all, spearman_corr_all), (delta_exp_all, delta_model_out_all) = get_linregress_stats(model, models_predictions[model], seq_val, False, filter_significant)\n",
        "        \n",
        "        # Prepare data for plotting\n",
        "        df_significant = pd.DataFrame({\n",
        "            'Expression Difference': delta_exp_significant,\n",
        "            'Model Output Difference': delta_model_out_significant\n",
        "        })\n",
        "        \n",
        "        df_all = pd.DataFrame({\n",
        "            'Expression Difference': delta_exp_all,\n",
        "            'Model Output Difference': delta_model_out_all\n",
        "        })\n",
        "\n",
        "        # Plot the regression with overlapping data\n",
        "        plot_regression(df_significant, df_all, model, r_val_significant, p_val_significant, r_val_all, p_val_all)\n",
        "        print('done')\n",
        "\n",
        "# Call the process_models function with your parameters\n",
        "process_models(models_names, models_predictions, np.log2(seq_val))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
